{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting paths and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "module_path\n",
    "\n",
    "os.chdir(module_path)\n",
    "\n",
    "# from src.evaluation.evaluator_manager import EvaluatorManager\n",
    "# from src.evaluation.future.evaluator_manager_do import EvaluatorManagers as PairedEvaluatorManager\n",
    "from src.utils.context import Context\n",
    "from src.data_analysis.future.data_analyzer import DataAnalyzer as data_analyzer\n",
    "\n",
    "from src.evaluation.future.evaluator_manager_triplets import EvaluatorManager\n",
    "\n",
    "config_f_name = 'generate_minimize/asd/dcm/dcm-lcls/generate_minimize0.jsonc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating context for: /Users/kevinmanzano/Programacion/GRETEL/lab/config/generate_minimize/asd/dmc/dmc-lcls/generate_minimize0.jsonc\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The provided config file does not exist. PATH: /Users/kevinmanzano/Programacion/GRETEL/lab/config/generate_minimize/asd/dmc/dmc-lcls/generate_minimize0.jsonc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m runno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating context for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m context\u001b[38;5;241m.\u001b[39mrun_number \u001b[38;5;241m=\u001b[39m runno\n\u001b[1;32m      8\u001b[0m context\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;241m.\u001b[39mconfig_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Run: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;241m.\u001b[39mrun_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programacion/GRETEL/src/utils/context.py:68\u001b[0m, in \u001b[0;36mContext.get_context\u001b[0;34m(cls, config_file)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mThe configuration file must be passed to the method as PATH the first time. Now you did not pass as parameter.\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m     Context\u001b[38;5;241m.\u001b[39m__global \u001b[38;5;241m=\u001b[39m \u001b[43mContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__create_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Context\u001b[38;5;241m.\u001b[39m__global\n",
      "File \u001b[0;32m~/Programacion/GRETEL/src/utils/context.py:38\u001b[0m, in \u001b[0;36mContext.__init__\u001b[0;34m(self, create_key, config_file)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Check that the path to the config file exists\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config_file):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mThe provided config file does not exist. PATH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'''\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_file \u001b[38;5;241m=\u001b[39m config_file\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Read the config dictionary inside the config path with the composer\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The provided config file does not exist. PATH: /Users/kevinmanzano/Programacion/GRETEL/lab/config/generate_minimize/asd/dmc/dmc-lcls/generate_minimize0.jsonc"
     ]
    }
   ],
   "source": [
    "config_path = os.path.join(module_path, 'lab', 'config', config_f_name)\n",
    "runno = 1\n",
    "    \n",
    "print(f\"Generating context for: {config_path}\")\n",
    "context = Context.get_context(config_path)\n",
    "context.run_number = runno\n",
    "\n",
    "context.logger.info(f\"Executing: {context.config_file} Run: {context.run_number}\")\n",
    "context.logger.info(\"Creating the evaluation manager....................................\")\n",
    "\n",
    "context.logger.info(\"Creating the evaluators......................................................\")\n",
    "eval_manager = EvaluatorManager(context)\n",
    "\n",
    "context.logger.info(\n",
    "    \"Evaluating the explainers.............................................................\"\n",
    ")\n",
    "eval_manager.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_inst = []\n",
    "for exp in eval_manager.evaluators[0]._explanations:\n",
    "    exp.input_instance._dataset = None\n",
    "    exp.counterfactual_instances[0]._dataset = None\n",
    "    \n",
    "exp_inst = [(exp.input_instance, exp.counterfactual_instances[0]) for exp in eval_manager.evaluators[0]._explanations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "pickle_path = os.path.join(module_path, 'lab', 'pickles', 'union.pkl')\n",
    "pickle_dir = os.path.dirname(pickle_path)\n",
    "\n",
    "if not os.path.exists(pickle_dir):\n",
    "    os.makedirs(pickle_dir)\n",
    "\n",
    "with open(pickle_path, 'wb') as pickle_file:\n",
    "    pickle.dump(exp_inst, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(module_path, 'lab', 'pickles', 'union.pkl'), 'rb') as clear_file:\n",
    "    clear_exp = pickle.load(clear_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = os.path.join(module_path, 'lab', 'output', 'results')\n",
    "stats_file_path = os.path.join(module_path, 'lab', 'stats', 'results.csv')\n",
    "res = data_analyzer.create_aggregated_dataframe(results_path)\n",
    "res.to_csv(stats_file_path)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing individual instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = eval_manager.evaluators[0]\n",
    "evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = evaluator.explanations[2]\n",
    "og_inst = exp.input_instance\n",
    "cf_inst = exp.counterfactual_instances[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'cf2.pkl'), 'rb') as cf2_file:\n",
    "    cf2_exp = pickle.load(cf2_file)\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'clear.pkl'), 'rb') as clear_file:\n",
    "    clear_exp = pickle.load(clear_file)\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'irand.pkl'), 'rb') as irand_file:\n",
    "    irand_exp = pickle.load(irand_file)\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'obs.pkl'), 'rb') as obs_file:\n",
    "    obs_exp = pickle.load(obs_file)\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'rsgg.pkl'), 'rb') as rsgg_file:\n",
    "    rsgg_exp = pickle.load(rsgg_file)\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'bidirectional.pkl'), 'rb') as bi_file:\n",
    "    bi_exp = pickle.load(bi_file)\n",
    "\n",
    "with open(os.path.join(module_path, 'lab', 'pickles', 'union.pkl'), 'rb') as union_file:\n",
    "    union_exp = pickle.load(union_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "\n",
    "og_inst = cf2_exp[i][0]\n",
    "cf2_cf = cf2_exp[i][1]\n",
    "print(og_inst.id, cf2_cf.id)\n",
    "\n",
    "clear_cf = clear_exp[i][1]\n",
    "print(clear_exp[i][0].id, clear_cf.id)\n",
    "\n",
    "irand_cf = irand_exp[i][1]\n",
    "print(irand_exp[i][0].id, irand_cf.id)\n",
    "\n",
    "obs_cf = obs_exp[i][1]\n",
    "print(obs_exp[i][0].id, obs_cf.id)\n",
    "\n",
    "rsgg_cf = rsgg_exp[i][1]\n",
    "print(rsgg_exp[i][0].id, rsgg_cf.id)\n",
    "\n",
    "union_cf = union_exp[i][1]\n",
    "print(union_exp[i][0].id, union_cf.id)\n",
    "\n",
    "bi_cf = bi_exp[i][1]\n",
    "print(bi_exp[i][0].id, bi_cf.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = data_analyzer.draw_graph(og_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, cf2_cf, position=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, clear_cf, position=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, irand_cf, position=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, obs_cf, position=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, rsgg_cf, position=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, union_cf, position=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, bi_cf, position=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Paper Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "changes = data_analyzer.get_cf_changes(og_inst, cf_inst, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_edges = changes['common edges']\n",
    "added_edges = changes['added edges']\n",
    "removed_edges = changes['removed edges']\n",
    "common_nodes = changes['common nodes']\n",
    "added_nodes = changes['added nodes']\n",
    "removed_nodes = changes['removed nodes']\n",
    "\n",
    "print(f'added edges: {added_edges}')\n",
    "print(f'removed_edges: {removed_edges}')\n",
    "print(f'added nodes: {added_nodes}')\n",
    "print(f'removed nodes: {removed_nodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = data_analyzer.draw_graph(og_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_analyzer.draw_counterfactual_actions(og_inst, cf_inst, position=pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
